{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm_notebook\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def dsigmoid(x):\n",
    "    return x * (1-x)\n",
    "\n",
    "# 2. Rectified Linear Unit Function\n",
    "def relu(x):\n",
    "     return abs(x) * (x > 0)\n",
    "\n",
    "def drelu(x):\n",
    "     return 1. * (x > 0.)\n",
    "\n",
    "# 3. Leaky-Relu Functions\n",
    "def lrelu(x):\n",
    "    return np.where(x > 0., x, x * 0.01)\n",
    "\n",
    "def dlrelu(x):\n",
    "    dx = np.ones_like(x)\n",
    "    dx[x < 0.] = 0.01\n",
    "    return dx\n",
    "\n",
    "# 4. Hyperbolic Tan Function\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def dtanh(x):\n",
    "    return 1.0 - (np.power(np.tanh(x),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_forward(data_in, w0,w1,w2, w3, b0,b1,b2,b3):\n",
    "    '''\n",
    "    The Feed-forward considers 5 layers including input and output layer.\n",
    "    \n",
    "    The output layer/neuron is a classification node.\n",
    "    \n",
    "    returns: state of each layer\n",
    "    '''\n",
    "    layer0 = data_in\n",
    "    layer1 = tanh(np.dot(layer0, w0)+b0)\n",
    "    layer2 = tanh(np.dot(layer1, w1)+b1)\n",
    "    layer3 = tanh(np.dot(layer2, w2)+b2)\n",
    "    layer4 = sigmoid(np.dot(layer3, w3)+b3)\n",
    "\n",
    "    return layer0, layer1, layer2, layer3, layer4\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backpropogate(i, layer0, layer1, layer2, layer3, layer4, actual_y, w0,w1,w2,w3,b0,b1,b2,b3, learning_rate):\n",
    "    '''\n",
    "    This backpropogate is only slightly different from a regular classifier\n",
    "    in ways in which the output layer gradient is calculated.\n",
    "    \n",
    "    Since the output layer is not a function of any activation function,\n",
    "    the delta doesn't need to be multiplied with the transfer derivative of the\n",
    "    output layer.\n",
    "    \n",
    "    The rest is all the same.\n",
    "    \n",
    "    returns: weights and bias matrices\n",
    "    '''\n",
    "    l4_error = layer4 - actual_y\n",
    "   \n",
    "    l4_delta = l4_error * dsigmoid(layer4)\n",
    "    dh4 = np.dot(layer3.T, l4_delta)\n",
    "    \n",
    "    l3_error = l4_delta.dot(w3.T)\n",
    "    l3_delta = l3_error * dtanh(layer3)\n",
    "    dh3 = np.dot(layer2.T, l3_delta)\n",
    "    \n",
    "    l2_error = l3_delta.dot(w2.T)\n",
    "    l2_delta = l2_error * dtanh(layer2)\n",
    "    dh2 = np.dot(layer1.T, l2_delta)\n",
    "    \n",
    "    l1_error = l2_delta.dot(w1.T)\n",
    "    l1_delta = l1_error * dtanh(layer1)\n",
    "    dh1 = np.dot(layer0.T, l1_delta)\n",
    "    \n",
    "    w3 = w3 - (learning_rate * dh4)\n",
    "    w2 = w2 - (learning_rate * dh3)\n",
    "    w1 = w1 - (learning_rate * dh2)\n",
    "    w0 = w0 - (learning_rate * dh1)\n",
    "    \n",
    "    b3 = b3 - (learning_rate * np.mean(l4_delta))\n",
    "    b2 = b2 - (learning_rate * np.mean(l3_delta))\n",
    "    b1 = b1 - (learning_rate * np.mean(l2_delta))\n",
    "    b0 = b0 - (learning_rate * np.mean(l1_delta))    \n",
    "\n",
    "    if i%10==0 and (i!=0):\n",
    "        loss = np.mean(np.power(layer4-actual_y, 2))\n",
    "        loss_curve.append(loss)\n",
    "        iters.append(int(i))\n",
    "        \n",
    "        if i%1000 == 0:\n",
    "            print(\"\\n\", int(i), loss)\n",
    "\n",
    "        \n",
    "    return w0, w1,w2,w3, b0,b1,b2,b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(testx, testy):\n",
    "    correct = 0\n",
    "    layer0, layer1, layer2, layer3, layer4 = feed_forward(testx,w0, w1,w2,w3, b0,b1,b2,b3)\n",
    "    for i in range(len(testx)):\n",
    "        if np.argmax(layer4[i]) == np.argmax(testy[i]):\n",
    "            correct +=1 \n",
    "            \n",
    "    return f\"Accuracy: {correct*100/len(testy)}%\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32561, 15)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2=pd.read_csv(\"adult.csv\",names=['age','workclass','fnlwgt','education','education-num','marital-status','occupation','relationship','race','sex','capital-gain','capital-loss','hours-per-week','native-country','target'])\n",
    "data2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30162, 15)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data2.replace(' ?', np.nan).dropna()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30162, 15)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['workclass', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country', 'target']\n",
    "#categorize\n",
    "for column in features:\n",
    "    data[column] = data[column].astype(\"category\").cat.codes\n",
    "#co relation    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data=data.drop(['education'],axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.03090513e-05, 3.36767237e-06, 1.83175782e-01, ...,\n",
       "        0.00000000e+00, 2.69413789e-05, 2.55943100e-05],\n",
       "       [1.68383618e-05, 1.34706895e-06, 4.50830300e-02, ...,\n",
       "        0.00000000e+00, 2.69413789e-05, 2.55943100e-05],\n",
       "       [1.27971550e-05, 0.00000000e+00, 1.45410031e-01, ...,\n",
       "        0.00000000e+00, 6.73534473e-06, 2.55943100e-05],\n",
       "       ...,\n",
       "       [3.03090513e-05, 1.34706895e-06, 2.15660350e-01, ...,\n",
       "        0.00000000e+00, 2.69413789e-05, 2.55943100e-05],\n",
       "       [3.09825858e-05, 2.69413789e-06, 3.07775619e-01, ...,\n",
       "        0.00000000e+00, 4.04120684e-05, 2.55943100e-05],\n",
       "       [3.03090513e-05, 1.34706895e-06, 2.21565900e-02, ...,\n",
       "        0.00000000e+00, 2.35737066e-05, 2.55943100e-05]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(final_data.drop(['target'],axis=1))\n",
    "Y = np.array(final_data['target'])\n",
    "nt=[]\n",
    "for i in Y:\n",
    "    op = [0,0]\n",
    "    op[i] = 1\n",
    "    nt.append(op)\n",
    "\n",
    "X = (X-X.min()) / (X.max()-X.min())\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X,nt, test_size=0.8)\n",
    "xtrain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_curve = []\n",
    "iters = []\n",
    "epochs = 10000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "w0 = np.random.random((13,50))\n",
    "w1 = np.random.random((50,30))\n",
    "w2 = np.random.random((30, 5))\n",
    "w3 = np.random.random((5,2))\n",
    "\n",
    "b0 = np.random.random((1,1))-1\n",
    "b1 = np.random.random((1,1))-1\n",
    "b2 = np.random.random((1,1))-1\n",
    "b3 = np.random.random((1,1))-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de50d7a2f8124e189eed46ade7b3ddd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1000 0.25580234810655955\n",
      "\n",
      " 2000 0.25580234763820414\n",
      "\n",
      " 3000 0.25580234714968303\n",
      "\n",
      " 4000 0.2558023458409432\n",
      "\n",
      " 5000 0.2558023456608269\n",
      "\n",
      " 6000 0.2558023448765259\n",
      "\n",
      " 7000 0.25580234453247486\n",
      "\n",
      " 8000 0.2558023439744775\n",
      "\n",
      " 9000 0.25580234340170827\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm_notebook(range(epochs)):\n",
    "    layer0, layer1, layer2, layer3, layer4 = feed_forward(xtrain, w0,w1,w2, w3, b0,b1,b2,b3)\n",
    "    w0,w1,w2, w3, b0,b1,b2,b3 = backpropogate(i,layer0, layer1, layer2, layer3, layer4, ytrain, w0,w1,w2, w3, b0,b1,b2,b3, 0.01 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1000)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(iters, loss_curve,'r')\n",
    "plt.xlim(0,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Accuracy: 74.41976127320955%'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Accuracy: 75.27973476999586%'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
